{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import utils\n",
    "import torchtext\n",
    "from data import dataset\n",
    "import tweet_utils as tu\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "train_dataset = dataset.DisasterData('train', path='data/')\n",
    "valid_dataset = dataset.DisasterData('valid', path='data/')\n",
    "test_dataset = dataset.DisasterData('test', path='data/')\n",
    "all_dataset = dataset.DisasterData('all', path='data/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(6851,\n ((9741,\n   'Back home they mad cause I chill with the white boys .',\n   'Orlando ',\n   'tragedy'),\n  0))"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset),train_dataset[6800]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(762,\n ((10769,\n   \"Check out 'Malaysia Confirms Plane Wreckage Is From Flight MH370' at  http://t.co/UB3woZ2UT1\",\n   'No ID, No VOTE!!!',\n   'wreckage'),\n  1))"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dataset),valid_dataset[680]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "(3263,\n ((9914,\n   'RT MMDA: ADVISORY: Stalled Bus at EDSA Service Road Cubao SB due to mechanical trouble as of 7:53 AM. 1 lane occupied. MMDA T/C on site. T\\x89Ã›_',\n   'City of Bacoor, CALABARZON PHL',\n   'trouble'),\n  None))"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset), test_dataset[3000]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "vec = torchtext.vocab.GloVe(name='6B', dim=300)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(300, 300)\n",
    "        self.fc2 = nn.Linear(300, 100)\n",
    "        self.fc3 = nn.Linear(100, 1)\n",
    "\n",
    "        self.dropout0 = nn.Dropout(.8)\n",
    "        self.dropout1 = nn.Dropout(.6)\n",
    "        self.dropout2 = nn.Dropout(.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout0(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    ids = []\n",
    "    xs = []\n",
    "    targets = []\n",
    "\n",
    "    for ((id, text, location, keyword), target) in batch:\n",
    "        tokens = tu.process_tweet(text, rm_weblinks=True).split()\n",
    "        x = sum([vec[token] for token in tokens]) / len(tokens)\n",
    "        ids.append([id])\n",
    "        xs.append([float(a) for a in x])\n",
    "        targets.append([target])\n",
    "\n",
    "    return torch.tensor(ids), torch.tensor(xs), torch.tensor(targets, dtype=torch.float) if targets[0][0] is not None else None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "train_dataloader = utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "all_dataloader = utils.data.DataLoader(all_dataset, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "valid_dataloader = utils.data.DataLoader(valid_dataset, batch_size=32, collate_fn=collate)\n",
    "test_dataloader = utils.data.DataLoader(test_dataset, batch_size=32, collate_fn=collate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[1054],\n         [9562],\n         [5545],\n         [3582],\n         [4556],\n         [8100],\n         [1588],\n         [7292],\n         [1479],\n         [5443],\n         [1126],\n         [7467],\n         [7595],\n         [4047],\n         [9038],\n         [3523],\n         [9435],\n         [1951],\n         [6430],\n         [8507],\n         [8350],\n         [7610],\n         [ 496],\n         [5416],\n         [5573],\n         [5067],\n         [9581],\n         [5918],\n         [7970],\n         [6150],\n         [5807],\n         [9244]]),\n tensor([[-0.0698,  0.0874, -0.0642,  ...,  0.0155, -0.0085,  0.2092],\n         [-0.0569,  0.0186, -0.1048,  ..., -0.1485,  0.0835,  0.4287],\n         [-0.0104,  0.1229, -0.0930,  ...,  0.0849, -0.0654,  0.0400],\n         ...,\n         [-0.0936, -0.0352, -0.0521,  ..., -0.1619, -0.0264,  0.1369],\n         [-0.1158, -0.0503, -0.0185,  ..., -0.2187, -0.0465,  0.0735],\n         [-0.1914,  0.0110, -0.1207,  ..., -0.1725, -0.0866,  0.0699]]),\n tensor([[0.],\n         [0.],\n         [0.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [1.],\n         [1.],\n         [0.],\n         [0.]]))"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def get_accuracy(model, dataloader):\n",
    "    accurate = 0\n",
    "    total = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for id, x, y in dataloader:\n",
    "            y_hat = torch.sigmoid(model.forward(x)).round()\n",
    "            accurate += float((y_hat == y).sum())\n",
    "            total += float(x.shape[0])\n",
    "\n",
    "    return accurate / total\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "model = Model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def train(epochs, model, optimizer, valid_dataloader, train_dataloader, loss_fn=nn.BCELoss(), display_epoch=0):\n",
    "    print(\"Initial validation accuracy:\", get_accuracy(model, valid_dataloader))\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        j = 0\n",
    "        epoch_loss = 0\n",
    "\n",
    "        model.train()\n",
    "        for id, x, y in train_dataloader:\n",
    "            y_hat = torch.sigmoid(model.forward(x))\n",
    "            loss = loss_fn(y_hat, y)\n",
    "\n",
    "            j += 1\n",
    "            epoch_loss += float(loss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        print('EPOCH', i + 1 + display_epoch, '| loss:',\n",
    "              round(epoch_loss / j, 4),\n",
    "              '| valid accuracy:',\n",
    "              round(get_accuracy(model, valid_dataloader), 4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial validation accuracy: 0.5406824146981627\n",
      "EPOCH 1 | loss: 0.6758 | valid accuracy: 0.6444\n",
      "EPOCH 2 | loss: 0.6234 | valid accuracy: 0.7454\n",
      "EPOCH 3 | loss: 0.5911 | valid accuracy: 0.7835\n",
      "EPOCH 4 | loss: 0.5671 | valid accuracy: 0.7782\n",
      "EPOCH 5 | loss: 0.567 | valid accuracy: 0.7835\n",
      "EPOCH 6 | loss: 0.5581 | valid accuracy: 0.7835\n",
      "EPOCH 7 | loss: 0.5616 | valid accuracy: 0.7782\n",
      "EPOCH 8 | loss: 0.5576 | valid accuracy: 0.7717\n",
      "EPOCH 9 | loss: 0.548 | valid accuracy: 0.7979\n",
      "EPOCH 10 | loss: 0.5432 | valid accuracy: 0.7887\n",
      "EPOCH 11 | loss: 0.5494 | valid accuracy: 0.7835\n",
      "EPOCH 12 | loss: 0.5501 | valid accuracy: 0.7887\n",
      "EPOCH 13 | loss: 0.5499 | valid accuracy: 0.7822\n",
      "EPOCH 14 | loss: 0.5456 | valid accuracy: 0.7848\n",
      "EPOCH 15 | loss: 0.5491 | valid accuracy: 0.773\n",
      "EPOCH 16 | loss: 0.5469 | valid accuracy: 0.7822\n",
      "EPOCH 17 | loss: 0.5459 | valid accuracy: 0.7848\n",
      "EPOCH 18 | loss: 0.5401 | valid accuracy: 0.7835\n",
      "EPOCH 19 | loss: 0.5407 | valid accuracy: 0.7848\n",
      "EPOCH 20 | loss: 0.5447 | valid accuracy: 0.7861\n",
      "EPOCH 21 | loss: 0.5442 | valid accuracy: 0.79\n",
      "EPOCH 22 | loss: 0.5364 | valid accuracy: 0.7861\n",
      "EPOCH 23 | loss: 0.5461 | valid accuracy: 0.7782\n",
      "EPOCH 24 | loss: 0.536 | valid accuracy: 0.7795\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [37], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisplay_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn [36], line 10\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(epochs, model, optimizer, valid_dataloader, train_dataloader, loss_fn, display_epoch)\u001B[0m\n\u001B[1;32m      7\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      9\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28mid\u001B[39m, x, y \u001B[38;5;129;01min\u001B[39;00m train_dataloader:\n\u001B[1;32m     11\u001B[0m     y_hat \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msigmoid(model\u001B[38;5;241m.\u001B[39mforward(x))\n\u001B[1;32m     12\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_fn(y_hat, y)\n",
      "File \u001B[0;32m~/Documents/Python/ML/MLEnv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/Documents/Python/ML/MLEnv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 671\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    673\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/Documents/Python/ML/MLEnv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:61\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 61\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn [30], line 7\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m      4\u001B[0m targets \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ((\u001B[38;5;28mid\u001B[39m, text, location, keyword), target) \u001B[38;5;129;01min\u001B[39;00m batch:\n\u001B[0;32m----> 7\u001B[0m     tokens \u001B[38;5;241m=\u001B[39m \u001B[43mtu\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_tweet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrm_weblinks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msplit()\n\u001B[1;32m      8\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m([vec[token] \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m tokens]) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(tokens)\n\u001B[1;32m      9\u001B[0m     ids\u001B[38;5;241m.\u001B[39mappend([\u001B[38;5;28mid\u001B[39m])\n",
      "File \u001B[0;32m~/Documents/Python/ML/KaggleCompetitions/DisasterTweets/tweet_utils.py:31\u001B[0m, in \u001B[0;36mprocess_tweet\u001B[0;34m(tweet, lower, rm_weblinks, keep_usernames, keep_hashtags)\u001B[0m\n\u001B[1;32m     28\u001B[0m res \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m#(\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mS*)\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mg<1>\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m keep_hashtags \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, res)\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# punctuation\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m(\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mS+?)[.,:;!?]+\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43ms|\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m     32\u001B[0m \u001B[43m             \u001B[49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m(\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mS+?)[.,:;!?]+$\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m             \u001B[49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mg<1>\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43mg<2> \u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m             \u001B[49m\u001B[43mres\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# parentheses\u001B[39;00m\n\u001B[1;32m     37\u001B[0m res \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m]()\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m]|\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     38\u001B[0m              \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]+|\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     39\u001B[0m              \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]+\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms|\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     40\u001B[0m              \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m]+$\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m, res)\n",
      "File \u001B[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/re.py:210\u001B[0m, in \u001B[0;36msub\u001B[0;34m(pattern, repl, string, count, flags)\u001B[0m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msub\u001B[39m(pattern, repl, string, count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, flags\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001B[39;00m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001B[39;00m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001B[39;00m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001B[39;00m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;124;03m    a callable, it's passed the Match object and must return\u001B[39;00m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;124;03m    a replacement string to be used.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 210\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_compile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpattern\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrepl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstring\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcount\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train(100, model, optimizer, valid_dataloader, train_dataloader, display_epoch=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the final model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=2e-2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train(100, model, optimizer, valid_dataloader, all_dataloader, display_epoch=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame()\n",
    "\n",
    "for ids, x, _ in test_dataloader:\n",
    "    y_hat = torch.sigmoid(model.forward(x)).round()\n",
    "    r = torch.concat([ids, y_hat], dim=1)\n",
    "    predictions_df = pd.concat([predictions_df, pd.DataFrame(r.detach().numpy(), columns=['id', 'target'])])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_df.target = predictions_df.target.astype(int)\n",
    "predictions_df.id = predictions_df.id.astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_df.to_csv('predictions/simple_feedforward_first.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
